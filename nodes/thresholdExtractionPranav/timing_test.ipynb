{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thresholdExtractionPranav import ThresholdExtraction\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[thresh_cross_4] INFO: Loading 4 order, 250 hz highpass acausal IIR-IIR filter\n",
      "[thresh_cross_4] INFO: Loaded thresholds from the thresholds stream\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[thresh_cross_4] Redis connection established on host: 192.168.30.6, port: 27263\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['tx', '-n', 'thresh_cross_4', '-i', '192.168.30.6', '-p', '27263']\n",
    "\n",
    "params = {'log': 'INFO',\n",
    " 'pack_per_call': 1,\n",
    " 'thresh_mult': -4.5,\n",
    " 'thresh_calc_len': 2000,\n",
    " 'butter_lowercut': 250,\n",
    " 'butter_uppercut': None,\n",
    " 'butter_order': 4,\n",
    " 'enable_CAR': False,\n",
    " 'output_filtered': False,\n",
    " 'acausal_filter_lag': 120,\n",
    " 'acausal_filter': 'IIR',\n",
    " 'input_name': 'reref_neural',\n",
    " 'input_chan_per_stream': 256,\n",
    " 'input_samp_per_stream': 30,\n",
    " 'input_samp_freq': 30000,\n",
    " 'input_data_type': 'float32',\n",
    " 'use_tracking_id': True,\n",
    " 'timestamp_data_type': 'uint64',\n",
    " 'sync_key': 'sync',\n",
    " 'time_key': 'ts',\n",
    " 'sync_source_id': 'nsp_idx_1',\n",
    " 'thresholds_stream': 'thresholds',\n",
    " 'neural_ch_range': [0, 96],\n",
    " 'thresholds_ch_range': [0, 96],\n",
    " 'n_channels': 96,\n",
    " 'ch_mask_stream': 'z_mask_stream'}\n",
    "\n",
    "node = ThresholdExtraction(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timing Statistics (in milliseconds):\n",
      "--------------------------------------------------------------------------------\n",
      "Operation                            Mean        Min        Max      Count\n",
      "--------------------------------------------------------------------------------\n",
      "INIT                                1.682      1.682      1.682          1\n",
      "INIT time                           0.105      0.105      0.105          1\n",
      "Redis read                          0.769      0.048      3.278      46357\n",
      "Data parsing                        0.012      0.008      0.327      46357\n",
      "Filtering                           0.133      0.112      0.529      46356\n",
      "Buffer updates                      0.001      0.001      0.276      46356\n",
      "Threshold detection                 0.024      0.017      0.366      46352\n",
      "Redis pipeline                      0.059      0.041      0.478      46352\n",
      "Threshold Extraction                0.999      0.236      3.891      46352\n",
      "Threshold Extraction2               1.000      0.237      5.046      46352\n",
      "Threshold Extraction3               1.000      0.237      3.891      46352\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2e1d716ff0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/emory-cart/brand-modules/brand-nsp/nodes/thresholdExtraction/thresholdExtractionPranav.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m                                         self.car_groups)\n\u001b[1;32m    558\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                         self.filter_func(data_buffer,\n\u001b[0m\u001b[1;32m    560\u001b[0m                                         \u001b[0mfilt_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                                         \u001b[0mrev_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/emory-cart/brand-modules/brand-nsp/nodes/thresholdExtraction/thresholdExtractionPranav.py\u001b[0m in \u001b[0;36macausal_filter\u001b[0;34m(data, filt_data, rev_buffer, sos, zi, group_list, rev_win, rev_zi)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrev_zi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilt_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             filt_data[:, ::-1] = scipy.signal.sosfilt(sos,\n\u001b[0m\u001b[1;32m    764\u001b[0m                                                       \u001b[0mrev_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                                                       \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/rt/lib/python3.8/site-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36msosfilt\u001b[0;34m(sos, x, axis, zi)\u001b[0m\n\u001b[1;32m   4028\u001b[0m     \u001b[0mzi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4029\u001b[0m     \u001b[0msos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4030\u001b[0;31m     \u001b[0m_sosfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4031\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "_=plt.hist(np.array(node.profiler.timings[\"Threshold Extraction3\"])*1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.004270 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "time.sleep(0.004)  # This is more precise than other sleep methods\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Elapsed time: {elapsed:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as  np \n",
    "\n",
    "256*150\n",
    "tes = np.arange(0, 150)\n",
    "test = np.tile(tes[:,None],256).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 30)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 30\n",
    "sample_number = 1\n",
    "start_idx = -chunk_size * sample_number\n",
    "end_idx = None if sample_number == 1 else -chunk_size * (sample_number - 1)\n",
    "test[:, start_idx:end_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52940/3062683339.py:5: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit(float64[:,:](\n",
      "/tmp/ipykernel_52940/3062683339.py:5: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"calculate_thresholds_numpy\" failed type inference due to: No implementation of function Function(<function mean at 0x7f49649105e0>) found for signature:\n",
      " \n",
      " >>> mean(array(float64, 2d, C), axis=Literal[int](1))\n",
      " \n",
      "There are 2 candidate implementations:\n",
      "      - Of which 2 did not match due to:\n",
      "      Overload in function 'array_mean': File: numba/np/arraymath.py: Line 425.\n",
      "        With argument(s): '(array(float64, 2d, C), axis=int64)':\n",
      "       Rejected as the implementation raised a specific error:\n",
      "         TypingError: got an unexpected keyword argument 'axis'\n",
      "  raised from /home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/typing/templates.py:784\n",
      "\n",
      "During: resolving callee type: Function(<function mean at 0x7f49649105e0>)\n",
      "During: typing of call at /tmp/ipykernel_52940/3062683339.py (15)\n",
      "\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/3062683339.py\", line 15:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit(float64[:,:](\n",
      "/home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"calculate_thresholds_numpy\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/3062683339.py\", line 5:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/3062683339.py\", line 5:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/decorators.py:282: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit, njit, float64, boolean, int64, prange\n",
    "import time\n",
    "\n",
    "@jit(float64[:,:](\n",
    "    float64[:,:], float64[:], float64[:,:], \n",
    "    int64, int64, boolean, float64\n",
    "\n",
    ")  , parallel=True)\n",
    "# 1. Numpy Vectorization Version\n",
    "def calculate_thresholds_numpy(filt_buffer, mean_squared_last, mean_squared_buffer, \n",
    "                             mean_squared_buffer_index, rms_window_len,\n",
    "                             mean_squared_buffer_full, thresh_mult):\n",
    "    \"\"\"Numpy vectorized version\"\"\"\n",
    "    mean_squared_new = np.mean(filt_buffer**2, axis=1)\n",
    "    \n",
    "    mean_squared_last += (mean_squared_new - \n",
    "                         mean_squared_buffer[:,mean_squared_buffer_index]) / rms_window_len\n",
    "    mean_squared_buffer[:,mean_squared_buffer_index] = mean_squared_new\n",
    "    \n",
    "    root_mean_squared = np.sqrt(mean_squared_last)\n",
    "    \n",
    "    if mean_squared_buffer_full:\n",
    "        return (thresh_mult * root_mean_squared).reshape(-1,1)\n",
    "    return np.zeros((filt_buffer.shape[0], 1))\n",
    "\n",
    "# 2. Numba Regular Loops Version\n",
    "@jit(float64[:,:](\n",
    "    float64[:,:], float64[:], float64[:,:], \n",
    "    int64, int64, boolean, float64\n",
    "),nopython=True)\n",
    "def calculate_thresholds_numba(filt_buffer, mean_squared_last, mean_squared_buffer, \n",
    "                             mean_squared_buffer_index, rms_window_len,\n",
    "                             mean_squared_buffer_full, thresh_mult):\n",
    "    \"\"\"Numba with regular loops\"\"\"\n",
    "    num_channels = filt_buffer.shape[0]\n",
    "    mean_squared_new = np.zeros(num_channels)\n",
    "    \n",
    "    # Calculate mean squared for each channel\n",
    "    for i in range(num_channels):\n",
    "        sum_squared = 0.0\n",
    "        for j in range(filt_buffer.shape[1]):\n",
    "            sum_squared += filt_buffer[i,j] * filt_buffer[i,j]\n",
    "        mean_squared_new[i] = sum_squared / filt_buffer.shape[1]\n",
    "    \n",
    "    # Update mean squared last\n",
    "    for i in range(num_channels):\n",
    "        mean_squared_last[i] += (mean_squared_new[i] - \n",
    "                               mean_squared_buffer[i,mean_squared_buffer_index]) / rms_window_len\n",
    "        mean_squared_buffer[i,mean_squared_buffer_index] = mean_squared_new[i]\n",
    "    \n",
    "    # Calculate thresholds\n",
    "    thresholds = np.zeros((num_channels, 1))\n",
    "    if mean_squared_buffer_full:\n",
    "        for i in range(num_channels):\n",
    "            thresholds[i,0] = thresh_mult * np.sqrt(mean_squared_last[i])\n",
    "            \n",
    "    return thresholds\n",
    "\n",
    "# 3. Numba Parallel Version\n",
    "@njit(float64[:,:](\n",
    "    float64[:,:], float64[:], float64[:,:], \n",
    "    int64, int64, boolean, float64\n",
    "),nopython=True)\n",
    "def calculate_thresholds_parallel(filt_buffer, mean_squared_last, mean_squared_buffer, \n",
    "                                mean_squared_buffer_index, rms_window_len,\n",
    "                                mean_squared_buffer_full, thresh_mult):\n",
    "    \"\"\"Numba with parallel processing\"\"\"\n",
    "    num_channels = filt_buffer.shape[0]\n",
    "    mean_squared_new = np.zeros(num_channels)\n",
    "    \n",
    "    # Calculate mean squared for each channel in parallel\n",
    "    for i in prange(num_channels):\n",
    "        sum_squared = 0.0\n",
    "        for j in range(filt_buffer.shape[1]):\n",
    "            sum_squared += filt_buffer[i,j] * filt_buffer[i,j]\n",
    "        mean_squared_new[i] = sum_squared / filt_buffer.shape[1]\n",
    "    \n",
    "    # Update mean squared last in parallel\n",
    "    for i in prange(num_channels):\n",
    "        mean_squared_last[i] += (mean_squared_new[i] - \n",
    "                               mean_squared_buffer[i,mean_squared_buffer_index]) / rms_window_len\n",
    "        mean_squared_buffer[i,mean_squared_buffer_index] = mean_squared_new[i]\n",
    "    \n",
    "    # Calculate thresholds\n",
    "    thresholds = np.zeros((num_channels, 1))\n",
    "    if mean_squared_buffer_full:\n",
    "        for i in prange(num_channels):\n",
    "            thresholds[i,0] = thresh_mult * np.sqrt(mean_squared_last[i])\n",
    "            \n",
    "    return thresholds\n",
    "\n",
    "# Benchmark function\n",
    "def benchmark_implementations(num_channels=64, buffer_size=1000, num_iterations=1000):\n",
    "    \"\"\"\n",
    "    Benchmark the different implementations\n",
    "    \"\"\"\n",
    "    # Setup test data\n",
    "    filt_buffer = np.random.randn(num_channels, buffer_size)\n",
    "    mean_squared_last = np.zeros(num_channels)\n",
    "    mean_squared_buffer = np.zeros((num_channels, buffer_size))\n",
    "    mean_squared_buffer_index = 0\n",
    "    rms_window_len = buffer_size\n",
    "    mean_squared_buffer_full = True\n",
    "    thresh_mult = 2.0\n",
    "    \n",
    "    # # Warm up JIT\n",
    "    # for _ in range(10):\n",
    "    #     calculate_thresholds_numba(filt_buffer.copy(), mean_squared_last.copy(), \n",
    "    #                              mean_squared_buffer.copy(), mean_squared_buffer_index,\n",
    "    #                              rms_window_len, mean_squared_buffer_full, thresh_mult)\n",
    "    #     calculate_thresholds_parallel(filt_buffer.copy(), mean_squared_last.copy(), \n",
    "    #                                 mean_squared_buffer.copy(), mean_squared_buffer_index,\n",
    "    #                                 rms_window_len, mean_squared_buffer_full, thresh_mult)\n",
    "    \n",
    "    # Benchmark each implementation\n",
    "    results = {}\n",
    "    \n",
    "    # Numpy vectorized\n",
    "    start = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        calculate_thresholds_numpy(filt_buffer, mean_squared_last, \n",
    "                                 mean_squared_buffer, mean_squared_buffer_index,\n",
    "                                 rms_window_len, mean_squared_buffer_full, thresh_mult)\n",
    "    results['numpy'] = (time.time() - start) / num_iterations\n",
    "    filt_buffer = np.random.randn(num_channels, buffer_size)\n",
    "    mean_squared_last = np.zeros(num_channels)\n",
    "    mean_squared_buffer = np.zeros((num_channels, buffer_size))\n",
    "    mean_squared_buffer_index = 0\n",
    "    rms_window_len = buffer_size\n",
    "    mean_squared_buffer_full = True\n",
    "    thresh_mult = 2.0\n",
    "    \n",
    "    # Numba loops\n",
    "    start = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        calculate_thresholds_numba(filt_buffer, mean_squared_last, \n",
    "                                 mean_squared_buffer, mean_squared_buffer_index,\n",
    "                                 rms_window_len, mean_squared_buffer_full, thresh_mult)\n",
    "    results['numba'] = (time.time() - start) / num_iterations\n",
    "    filt_buffer = np.random.randn(num_channels, buffer_size)\n",
    "    mean_squared_last = np.zeros(num_channels)\n",
    "    mean_squared_buffer = np.zeros((num_channels, buffer_size))\n",
    "    mean_squared_buffer_index = 0\n",
    "    rms_window_len = buffer_size\n",
    "    mean_squared_buffer_full = True\n",
    "    thresh_mult = 2.0\n",
    "    \n",
    "    # Numba parallel\n",
    "    start = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        calculate_thresholds_parallel(filt_buffer, mean_squared_last, \n",
    "                                    mean_squared_buffer, mean_squared_buffer_index,\n",
    "                                    rms_window_len, mean_squared_buffer_full, thresh_mult)\n",
    "    results['numba_parallel'] = (time.time() - start) / num_iterations\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 0.031491756439208984 ms per iteration\n",
      "numba: 0.0039942264556884766 ms per iteration\n",
      "numba_parallel: 0.0033864974975585938 ms per iteration\n"
     ]
    }
   ],
   "source": [
    "results = benchmark_implementations(num_channels=256, buffer_size=30)\n",
    "for impl, times in results.items():\n",
    "    print(f\"{impl}: {times*1000} ms per iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 0.0330355167388916 ms per iteration\n",
      "numba: 0.007925033569335938 ms per iteration\n",
      "numba_parallel: 0.00760197639465332 ms per iteration\n"
     ]
    }
   ],
   "source": [
    "results = benchmark_implementations(num_channels=256, buffer_size=30)\n",
    "for impl, times in results.items():\n",
    "    print(f\"{impl}: {times*1000} ms per iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark Results (milliseconds per iteration):\n",
      "------------------------------------------------------------\n",
      "\n",
      "NUMPY:\n",
      "  Mean ± Std: 0.019634715716044106 ± 0.0033634439995287027\n",
      "  Median: 0.018\n",
      "  Range: [0.016, 0.034]\n",
      "  95% CI: [0.018, 0.021]\n",
      "\n",
      "NUMBA:\n",
      "  Mean ± Std: 0.0036502917607625323 ± 0.0003902041806947258\n",
      "  Median: 0.004\n",
      "  Range: [0.003, 0.005]\n",
      "  95% CI: [0.004, 0.004]\n",
      "\n",
      "NUMBA_PARALLEL:\n",
      "  Mean ± Std: 0.0035590648651123045 ± 0.0004785038169194909\n",
      "  Median: 0.003\n",
      "  Range: [0.003, 0.005]\n",
      "  95% CI: [0.003, 0.004]\n",
      "\n",
      "Relative Performance (normalized to NumPy):\n",
      "------------------------------------------------------------\n",
      "numpy: 1.0x\n",
      "numba: 5.378944205803014x\n",
      "numba_parallel: 5.516818731940853x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def run_statistical_benchmark(num_channels=256, buffer_size=30, num_trials=30, num_iterations=1000):\n",
    "    \"\"\"\n",
    "    Run multiple trials of benchmarking and compute statistics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_channels : int\n",
    "        Number of channels in the data\n",
    "    buffer_size : int\n",
    "        Size of the buffer\n",
    "    num_trials : int\n",
    "        Number of times to repeat the entire benchmark\n",
    "    num_iterations : int\n",
    "        Number of iterations per trial\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Statistics for each implementation\n",
    "    \"\"\"\n",
    "    # Store results for each trial\n",
    "    results = {\n",
    "        'numpy': [],\n",
    "        'numba': [],\n",
    "        'numba_parallel': []\n",
    "    }\n",
    "    \n",
    "    # Run multiple trials\n",
    "    for trial in range(num_trials):\n",
    "        trial_results = benchmark_implementations(\n",
    "            num_channels=num_channels, \n",
    "            buffer_size=buffer_size,\n",
    "            num_iterations=num_iterations\n",
    "        )\n",
    "        \n",
    "        for impl in results:\n",
    "            results[impl].append(trial_results[impl] * 1000)  # Convert to ms\n",
    "            \n",
    "    # Calculate statistics\n",
    "    stats_results = {}\n",
    "    for impl, times in results.items():\n",
    "        times = np.array(times)\n",
    "        stats_results[impl] = {\n",
    "            'mean': np.mean(times),\n",
    "            'std': np.std(times),\n",
    "            'median': np.median(times),\n",
    "            'min': np.min(times),\n",
    "            'max': np.max(times),\n",
    "            'ci_95': stats.t.interval(\n",
    "                0.95, \n",
    "                len(times)-1, \n",
    "                loc=np.mean(times), \n",
    "                scale=stats.sem(times)\n",
    "            )\n",
    "        }\n",
    "        \n",
    "    return stats_results\n",
    "\n",
    "# Run the statistical benchmark\n",
    "stats_results = run_statistical_benchmark(\n",
    "    num_channels=256, \n",
    "    buffer_size=30, \n",
    "    num_trials=30,\n",
    "    num_iterations=1000\n",
    ")\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nBenchmark Results (milliseconds per iteration):\")\n",
    "print(\"-\" * 60)\n",
    "for impl, stats_dict in stats_results.items():\n",
    "    print(f\"\\n{impl.upper()}:\")\n",
    "    print(f\"  Mean ± Std: {stats_dict['mean']} ± {stats_dict['std']}\")\n",
    "    print(f\"  Median: {stats_dict['median']:.3f}\")\n",
    "    print(f\"  Range: [{stats_dict['min']:.3f}, {stats_dict['max']:.3f}]\")\n",
    "    print(f\"  95% CI: [{stats_dict['ci_95'][0]:.3f}, {stats_dict['ci_95'][1]:.3f}]\")\n",
    "\n",
    "# Calculate relative performance\n",
    "baseline = stats_results['numpy']['mean']\n",
    "print(\"\\nRelative Performance (normalized to NumPy):\")\n",
    "print(\"-\" * 60)\n",
    "for impl, stats_dict in stats_results.items():\n",
    "    relative = baseline / stats_dict['mean']\n",
    "    print(f\"{impl}: {relative:}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52940/1551340056.py:22: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit(int16[:](float64[:,:], float64[:,:]))\n",
      "/tmp/ipykernel_52940/1551340056.py:39: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit(int16[:](float64[:,:], float64[:,:]), parallel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossing Detection Benchmark Results (milliseconds per iteration):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "NUMPY:\n",
      "  Mean ± Std: 0.006376727422078451 ± 0.02106855036982988\n",
      "  Median: 0.003\n",
      "  Range: [0.002, 0.120]\n",
      "  95% CI: [-0.002, 0.014]\n",
      "\n",
      "NUMBA:\n",
      "  Mean ± Std: 0.002399897575378418 ± 0.0007850833120321406\n",
      "  Median: 0.002\n",
      "  Range: [0.001, 0.005]\n",
      "  95% CI: [0.002, 0.003]\n",
      "\n",
      "NUMBA_PARALLEL:\n",
      "  Mean ± Std: 0.019684775670369466 ± 0.033935952585662774\n",
      "  Median: 0.008\n",
      "  Range: [0.004, 0.166]\n",
      "  95% CI: [0.007, 0.033]\n",
      "\n",
      "HYBRID:\n",
      "  Mean ± Std: 0.0024316151936848956 ± 0.0007238741228969975\n",
      "  Median: 0.003\n",
      "  Range: [0.002, 0.005]\n",
      "  95% CI: [0.002, 0.003]\n",
      "\n",
      "Relative Performance (normalized to NumPy):\n",
      "----------------------------------------------------------------------\n",
      "numpy: 1.0x\n",
      "numba: 2.6570831553396452x\n",
      "numba_parallel: 0.3239420925521152x\n",
      "hybrid: 2.6224245672750093x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit, prange, boolean, int16, float64\n",
    "import time\n",
    "\n",
    "# 4. Hybrid Version (Numba with some vectorization)\n",
    "@njit()\n",
    "def detect_crossings_numpy(filt_buffer, thresholds):\n",
    "    \"\"\"Numba parallel version of threshold crossing detection\"\"\"\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    cross_now = np.zeros(num_channels, dtype=np.int16)\n",
    "    \n",
    "    for i in prange(num_channels):\n",
    "        threshold = thresholds[i, 0]\n",
    "        for j in range(1, buffer_size):\n",
    "            if filt_buffer[i, j] < threshold and filt_buffer[i, j-1] >= threshold:\n",
    "                cross_now[i] = 1\n",
    "                break\n",
    "    \n",
    "    return cross_now\n",
    "\n",
    "# 2. Numba Regular Loops Version\n",
    "@jit(int16[:](float64[:,:], float64[:,:]))\n",
    "def detect_crossings_numba(filt_buffer, thresholds):\n",
    "    \"\"\"Numba optimized version with regular loops\"\"\"\n",
    "\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    cross_now = np.zeros(num_channels, dtype=np.int16)\n",
    "    \n",
    "    for i in range(num_channels):\n",
    "        threshold = thresholds[i, 0]\n",
    "        for j in range(1, buffer_size):\n",
    "            if filt_buffer[i, j] < threshold and filt_buffer[i, j-1] >= threshold:\n",
    "                cross_now[i] = 1\n",
    "                break\n",
    "    \n",
    "    return cross_now\n",
    "\n",
    "# 3. Numba Parallel Version\n",
    "@jit(int16[:](float64[:,:], float64[:,:]), parallel=True)\n",
    "def detect_crossings_parallel(filt_buffer, thresholds):\n",
    "    \"\"\"Numba parallel version of threshold crossing detection\"\"\"\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    cross_now = np.zeros(num_channels, dtype=np.int16)\n",
    "    \n",
    "    for i in prange(num_channels):\n",
    "        threshold = thresholds[i, 0]\n",
    "        for j in range(1, buffer_size):\n",
    "            if filt_buffer[i, j] < threshold and filt_buffer[i, j-1] >= threshold:\n",
    "                cross_now[i] = 1\n",
    "                break\n",
    "    \n",
    "    return cross_now\n",
    "\n",
    "# 4. Hybrid Version (Numba with some vectorization)\n",
    "@njit(int16[:](float64[:,:], float64[:,:]))\n",
    "def detect_crossings_hybrid(filt_buffer, thresholds):\n",
    "    \"\"\"Numba parallel version of threshold crossing detection\"\"\"\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    cross_now = np.zeros(num_channels, dtype=np.int16)\n",
    "    \n",
    "    for i in prange(num_channels):\n",
    "        threshold = thresholds[i, 0]\n",
    "        for j in range(1, buffer_size):\n",
    "            if filt_buffer[i, j] < threshold and filt_buffer[i, j-1] >= threshold:\n",
    "                cross_now[i] = 1\n",
    "                break\n",
    "    \n",
    "    return cross_now\n",
    "\n",
    "def benchmark_crossing_implementations(num_channels=256, buffer_size=30, num_trials=30, num_iterations=1000):\n",
    "    \"\"\"\n",
    "    Benchmark different implementations of threshold crossing detection\n",
    "    \"\"\"\n",
    "    # Setup test data\n",
    "    filt_buffer = np.random.randn(num_channels, buffer_size)\n",
    "    thresholds = np.random.randn(num_channels, 1) * 0.5\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'numpy': [],\n",
    "        'numba': [],\n",
    "        'numba_parallel': [],\n",
    "        'hybrid': []\n",
    "    }\n",
    "    \n",
    "    # Warm up JIT\n",
    "    # for _ in range(10):\n",
    "    #     detect_crossings_numba(filt_buffer, thresholds)\n",
    "    #     detect_crossings_parallel(filt_buffer, thresholds)\n",
    "    #     detect_crossings_hybrid(filt_buffer, thresholds)\n",
    "    \n",
    "    # Run trials\n",
    "    for trial in range(num_trials):\n",
    "        # Numpy version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            detect_crossings_numpy(filt_buffer, thresholds)\n",
    "        results['numpy'].append((time.time() - start) * 1000 / num_iterations)\n",
    "        \n",
    "        # Numba version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            detect_crossings_numba(filt_buffer, thresholds)\n",
    "        results['numba'].append((time.time() - start) * 1000 / num_iterations)\n",
    "        \n",
    "        # Parallel version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            detect_crossings_parallel(filt_buffer, thresholds)\n",
    "        results['numba_parallel'].append((time.time() - start) * 1000 / num_iterations)\n",
    "        \n",
    "        # Hybrid version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            detect_crossings_hybrid(filt_buffer, thresholds)\n",
    "        results['hybrid'].append((time.time() - start) * 1000 / num_iterations)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats_results = {}\n",
    "    for impl, times in results.items():\n",
    "        times = np.array(times)\n",
    "        stats_results[impl] = {\n",
    "            'mean': np.mean(times),\n",
    "            'std': np.std(times),\n",
    "            'median': np.median(times),\n",
    "            'min': np.min(times),\n",
    "            'max': np.max(times),\n",
    "            'ci_95': stats.t.interval(\n",
    "                0.95, \n",
    "                len(times)-1, \n",
    "                loc=np.mean(times), \n",
    "                scale=stats.sem(times)\n",
    "            )\n",
    "        }\n",
    "        \n",
    "    return stats_results\n",
    "\n",
    "# Run benchmark\n",
    "stats_results = benchmark_crossing_implementations(\n",
    "    num_channels=256,\n",
    "    buffer_size=30,\n",
    "    num_trials=30,\n",
    "    num_iterations=1000\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nCrossing Detection Benchmark Results (milliseconds per iteration):\")\n",
    "print(\"-\" * 70)\n",
    "for impl, stats_dict in stats_results.items():\n",
    "    print(f\"\\n{impl.upper()}:\")\n",
    "    print(f\"  Mean ± Std: {stats_dict['mean']} ± {stats_dict['std']}\")\n",
    "    print(f\"  Median: {stats_dict['median']:.3f}\")\n",
    "    print(f\"  Range: [{stats_dict['min']:.3f}, {stats_dict['max']:.3f}]\")\n",
    "    print(f\"  95% CI: [{stats_dict['ci_95'][0]:.3f}, {stats_dict['ci_95'][1]:.3f}]\")\n",
    "\n",
    "# Calculate relative performance\n",
    "baseline = stats_results['numpy']['mean']\n",
    "print(\"\\nRelative Performance (normalized to NumPy):\")\n",
    "print(\"-\" * 70)\n",
    "for impl, stats_dict in stats_results.items():\n",
    "    relative = baseline / stats_dict['mean']\n",
    "    print(f\"{impl}: {relative}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52940/570491558.py:14: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit(float64[:](float64[:,:], boolean))\n",
      "/tmp/ipykernel_52940/570491558.py:35: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def calculate_power_parallel(filt_buffer, logscale):\n",
      "/tmp/ipykernel_52940/570491558.py:54: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit(float64[:](float64[:,:], boolean))\n",
      "/tmp/ipykernel_52940/570491558.py:54: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"calculate_power_hybrid\" failed type inference due to: No implementation of function Function(<function mean at 0x7f49649105e0>) found for signature:\n",
      " \n",
      " >>> mean(array(float64, 2d, C), axis=Literal[int](1))\n",
      " \n",
      "There are 2 candidate implementations:\n",
      "      - Of which 2 did not match due to:\n",
      "      Overload in function 'array_mean': File: numba/np/arraymath.py: Line 425.\n",
      "        With argument(s): '(array(float64, 2d, C), axis=int64)':\n",
      "       Rejected as the implementation raised a specific error:\n",
      "         TypingError: got an unexpected keyword argument 'axis'\n",
      "  raised from /home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/typing/templates.py:784\n",
      "\n",
      "During: resolving callee type: Function(<function mean at 0x7f49649105e0>)\n",
      "During: typing of call at /tmp/ipykernel_52940/570491558.py (62)\n",
      "\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/570491558.py\", line 62:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit(float64[:](float64[:,:], boolean))\n",
      "/tmp/ipykernel_52940/570491558.py:54: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"calculate_power_hybrid\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/570491558.py\", line 65:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit(float64[:](float64[:,:], boolean))\n",
      "/home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"calculate_power_hybrid\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/570491558.py\", line 54:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/vanar/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../../../tmp/ipykernel_52940/570491558.py\", line 54:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running benchmarks for linear scale...\n",
      "\n",
      "Running benchmarks for log scale...\n",
      "\n",
      "Linear Scale Results (milliseconds per iteration):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "NUMPY:\n",
      "  Mean ± Std: 0.012447079022725424 ± 0.0016272688029233932\n",
      "  Median: 0.012\n",
      "  Range: [0.011, 0.020]\n",
      "  95% CI: [0.012, 0.013]\n",
      "  Relative to NumPy: 1.00x\n",
      "\n",
      "NUMBA:\n",
      "  Mean ± Std: 0.0029752175013224285 ± 0.0006479974682155426\n",
      "  Median: 0.003\n",
      "  Range: [0.002, 0.006]\n",
      "  95% CI: [0.003, 0.003]\n",
      "  Relative to NumPy: 4.18x\n",
      "\n",
      "NUMBA_PARALLEL:\n",
      "  Mean ± Std: 0.006543270746866862 ± 0.020822918681311354\n",
      "  Median: 0.003\n",
      "  Range: [0.002, 0.119]\n",
      "  95% CI: [-0.001, 0.014]\n",
      "  Relative to NumPy: 1.90x\n",
      "\n",
      "HYBRID:\n",
      "  Mean ± Std: 0.015427438418070476 ± 0.0020421363442553525\n",
      "  Median: 0.015\n",
      "  Range: [0.014, 0.025]\n",
      "  95% CI: [0.015, 0.016]\n",
      "  Relative to NumPy: 0.81x\n",
      "\n",
      "Log Scale Results (milliseconds per iteration):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "NUMPY:\n",
      "  Mean ± Std: 0.016300058364868163 ± 0.0012138387788105493\n",
      "  Median: 0.016\n",
      "  Range: [0.014, 0.019]\n",
      "  95% CI: [0.016, 0.017]\n",
      "  Relative to NumPy: 1.00x\n",
      "\n",
      "NUMBA:\n",
      "  Mean ± Std: 0.005896584192911784 ± 0.0005703485970159702\n",
      "  Median: 0.006\n",
      "  Range: [0.005, 0.009]\n",
      "  95% CI: [0.006, 0.006]\n",
      "  Relative to NumPy: 2.76x\n",
      "\n",
      "NUMBA_PARALLEL:\n",
      "  Mean ± Std: 0.006180461247762044 ± 0.0012710921889846538\n",
      "  Median: 0.006\n",
      "  Range: [0.005, 0.012]\n",
      "  95% CI: [0.006, 0.007]\n",
      "  Relative to NumPy: 2.64x\n",
      "\n",
      "HYBRID:\n",
      "  Mean ± Std: 0.02138541539510091 ± 0.02096330260659086\n",
      "  Median: 0.017\n",
      "  Range: [0.015, 0.134]\n",
      "  95% CI: [0.013, 0.029]\n",
      "  Relative to NumPy: 0.76x\n",
      "\n",
      "Numerical Accuracy (max absolute difference from NumPy):\n",
      "----------------------------------------------------------------------\n",
      "numba_max_diff: 2.22e-15\n",
      "parallel_max_diff: 2.22e-15\n",
      "hybrid_max_diff: 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit, prange, float64, boolean\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# 1. Numpy Vectorized Version\n",
    "def calculate_power_numpy(filt_buffer, logscale=False):\n",
    "    \"\"\"Numpy vectorized version of power calculation\"\"\"\n",
    "    if logscale:\n",
    "        return 10 * np.log10(np.square(filt_buffer).mean(axis=1))\n",
    "    return np.square(filt_buffer).mean(axis=1)\n",
    "\n",
    "# 2. Numba Regular Loops Version\n",
    "@jit(float64[:](float64[:,:], boolean))\n",
    "def calculate_power_numba(filt_buffer, logscale):\n",
    "    \"\"\"Numba optimized version with regular loops\"\"\"\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    power = np.zeros(num_channels)\n",
    "    \n",
    "    for i in range(num_channels):\n",
    "        sum_squared = 0.0\n",
    "        for j in range(buffer_size):\n",
    "            sum_squared += filt_buffer[i,j] * filt_buffer[i,j]\n",
    "        \n",
    "        mean_power = sum_squared / buffer_size\n",
    "        if logscale:\n",
    "            power[i] = 10 * np.log10(mean_power)\n",
    "        else:\n",
    "            power[i] = mean_power\n",
    "            \n",
    "    return power\n",
    "\n",
    "# 3. Numba Parallel Version\n",
    "@jit\n",
    "def calculate_power_parallel(filt_buffer, logscale):\n",
    "    \"\"\"Numba parallel version of power calculation\"\"\"\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    power = np.zeros(num_channels)\n",
    "    \n",
    "    for i in prange(num_channels):\n",
    "        sum_squared = 0.0\n",
    "        for j in range(buffer_size):\n",
    "            sum_squared += filt_buffer[i,j] * filt_buffer[i,j]\n",
    "            \n",
    "        mean_power = sum_squared / buffer_size\n",
    "        if logscale:\n",
    "            power[i] = 10 * np.log10(mean_power)\n",
    "        else:\n",
    "            power[i] = mean_power\n",
    "            \n",
    "    return power\n",
    "\n",
    "# 4. Hybrid Version (Numba with partial vectorization)\n",
    "@jit(float64[:](float64[:,:], boolean))\n",
    "def calculate_power_hybrid(filt_buffer, logscale):\n",
    "    \"\"\"Hybrid approach using both Numba and some vectorization\"\"\"\n",
    "    num_channels = filt_buffer.shape[0]\n",
    "    power = np.zeros(num_channels)\n",
    "    \n",
    "    # Use vectorized operations along buffer axis\n",
    "    squared = filt_buffer * filt_buffer\n",
    "    mean_power = np.mean(squared, axis=1)\n",
    "    \n",
    "    if logscale:\n",
    "        for i in range(num_channels):\n",
    "            power[i] = 10 * np.log10(mean_power[i])\n",
    "    else:\n",
    "        power[:] = mean_power\n",
    "        \n",
    "    return power\n",
    "\n",
    "def benchmark_power_implementations(num_channels=256, buffer_size=30, num_trials=30, \n",
    "                                 num_iterations=1000, logscale=True):\n",
    "    \"\"\"\n",
    "    Benchmark different implementations of band power calculation\n",
    "    \"\"\"\n",
    "    # Setup test data\n",
    "    filt_buffer = np.random.randn(num_channels, buffer_size)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'numpy': [],\n",
    "        'numba': [],\n",
    "        'numba_parallel': [],\n",
    "        'hybrid': []\n",
    "    }\n",
    "    \n",
    "    # Warm up JIT\n",
    "    # for _ in range(10):\n",
    "    #     calculate_power_numba(filt_buffer, logscale)\n",
    "    #     calculate_power_parallel(filt_buffer, logscale)\n",
    "    #     calculate_power_hybrid(filt_buffer, logscale)\n",
    "    \n",
    "    # Run trials\n",
    "    for trial in range(num_trials):\n",
    "        # Numpy version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            calculate_power_numpy(filt_buffer, logscale)\n",
    "        results['numpy'].append((time.time() - start) * 1000 / num_iterations)\n",
    "        \n",
    "        # Numba version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            calculate_power_numba(filt_buffer, logscale)\n",
    "        results['numba'].append((time.time() - start) * 1000 / num_iterations)\n",
    "        \n",
    "        # Parallel version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            calculate_power_parallel(filt_buffer, logscale)\n",
    "        results['numba_parallel'].append((time.time() - start) * 1000 / num_iterations)\n",
    "        \n",
    "        # Hybrid version\n",
    "        start = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            calculate_power_hybrid(filt_buffer, logscale)\n",
    "        results['hybrid'].append((time.time() - start) * 1000 / num_iterations)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats_results = {}\n",
    "    for impl, times in results.items():\n",
    "        times = np.array(times)\n",
    "        stats_results[impl] = {\n",
    "            'mean': np.mean(times),\n",
    "            'std': np.std(times),\n",
    "            'median': np.median(times),\n",
    "            'min': np.min(times),\n",
    "            'max': np.max(times),\n",
    "            'ci_95': stats.t.interval(\n",
    "                0.95, \n",
    "                len(times)-1, \n",
    "                loc=np.mean(times), \n",
    "                scale=stats.sem(times)\n",
    "            ) if len(times) > 1 else (np.mean(times), np.mean(times))\n",
    "        }\n",
    "        \n",
    "    return stats_results\n",
    "\n",
    "# Function to compare numerical accuracy\n",
    "def compare_accuracy(num_channels=256, buffer_size=30, logscale=True):\n",
    "    \"\"\"Compare numerical accuracy between implementations\"\"\"\n",
    "    filt_buffer = np.random.randn(num_channels, buffer_size)\n",
    "    \n",
    "    # Get results from each implementation\n",
    "    numpy_result = calculate_power_numpy(filt_buffer, logscale)\n",
    "    numba_result = calculate_power_numba(filt_buffer, logscale)\n",
    "    parallel_result = calculate_power_parallel(filt_buffer, logscale)\n",
    "    hybrid_result = calculate_power_hybrid(filt_buffer, logscale)\n",
    "    \n",
    "    # Compare with numpy as reference\n",
    "    results = {\n",
    "        'numba_max_diff': np.max(np.abs(numpy_result - numba_result)),\n",
    "        'parallel_max_diff': np.max(np.abs(numpy_result - parallel_result)),\n",
    "        'hybrid_max_diff': np.max(np.abs(numpy_result - hybrid_result))\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmarks for both linear and log scale\n",
    "print(\"\\nRunning benchmarks for linear scale...\")\n",
    "linear_stats = benchmark_power_implementations(logscale=False)\n",
    "print(\"\\nRunning benchmarks for log scale...\")\n",
    "log_stats = benchmark_power_implementations(logscale=True)\n",
    "\n",
    "# Print results\n",
    "for scale, stats in [(\"Linear Scale\", linear_stats), (\"Log Scale\", log_stats)]:\n",
    "    print(f\"\\n{scale} Results (milliseconds per iteration):\")\n",
    "    print(\"-\" * 70)\n",
    "    baseline = stats['numpy']['mean']\n",
    "    for impl, stats_dict in stats.items():\n",
    "        print(f\"\\n{impl.upper()}:\")\n",
    "        print(f\"  Mean ± Std: {stats_dict['mean']} ± {stats_dict['std']}\")\n",
    "        print(f\"  Median: {stats_dict['median']:.3f}\")\n",
    "        print(f\"  Range: [{stats_dict['min']:.3f}, {stats_dict['max']:.3f}]\")\n",
    "        print(f\"  95% CI: [{stats_dict['ci_95'][0]:.3f}, {stats_dict['ci_95'][1]:.3f}]\")\n",
    "        print(f\"  Relative to NumPy: {baseline/stats_dict['mean']:.2f}x\")\n",
    "\n",
    "# Check numerical accuracy\n",
    "accuracy_results = compare_accuracy()\n",
    "print(\"\\nNumerical Accuracy (max absolute difference from NumPy):\")\n",
    "print(\"-\" * 70)\n",
    "for impl, diff in accuracy_results.items():\n",
    "    print(f\"{impl}: {diff:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit(int16[:](float64[:,:], float64[:]))\n",
    "def get_threshold_crossing(filt_buffer, thresholds ):\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    cross_now = np.zeros(num_channels, dtype=np.int16)\n",
    "    \n",
    "    for i in range(num_channels):\n",
    "        threshold = thresholds[i]\n",
    "        for j in range(1, buffer_size):\n",
    "            if filt_buffer[i, j] < threshold and filt_buffer[i, j-1] >= threshold:\n",
    "                cross_now[i] = 1\n",
    "                break\n",
    "    \n",
    "    return cross_now\n",
    "\n",
    "\n",
    "\n",
    "@njit(float64[:](float64[:,:], float64[:], boolean))\n",
    "def get_spike_bandpower(filt_buffer, power_buffer, logscale=False):\n",
    "    num_channels, buffer_size = filt_buffer.shape\n",
    "    \n",
    "    for i in range(num_channels):\n",
    "        sum_squared = 0.0\n",
    "        for j in range(buffer_size):\n",
    "            if logscale:\n",
    "                sum_squared += 10* np.log10(filt_buffer[i,j] * filt_buffer[i,j])\n",
    "            else:\n",
    "                sum_squared += filt_buffer[i,j] * filt_buffer[i,j]\n",
    "        \n",
    "        mean_power = sum_squared / buffer_size\n",
    "        power_buffer[i] = mean_power\n",
    "    return power_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nNo conversion from array(float64, 2d, C) to array(int64, 1d, A) for '$88return_value.3', defined at None\n\nFile \"../../../../../../../../tmp/ipykernel_52940/1606340820.py\", line 14:\n<source missing, REPL/exec in use?>\n\nDuring: typing of assignment at /tmp/ipykernel_52940/1606340820.py (14)\n\nFile \"../../../../../../../../tmp/ipykernel_52940/1606340820.py\", line 14:\n<source missing, REPL/exec in use?>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129;43m@njit\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mget_spike_bandpower\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilt_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# num_channels, buffer_size = filt_buffer.shape\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# logscale=False\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/decorators.py:241\u001b[0m, in \u001b[0;36m_jit.<locals>.wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m typeinfer\u001b[38;5;241m.\u001b[39mregister_dispatcher(disp):\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m sigs:\n\u001b[0;32m--> 241\u001b[0m             \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m         disp\u001b[38;5;241m.\u001b[39mdisable_compile()\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disp\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/dispatcher.py:965\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ev\u001b[38;5;241m.\u001b[39mtrigger_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumba:compile\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mev_details):\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m         cres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mForceLiteralArg \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfolded\u001b[39m(args, kws):\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/dispatcher.py:129\u001b[0m, in \u001b[0;36m_FunctionCompiler.compile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/dispatcher.py:139\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_cached\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mTypingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_failed_cache[key] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/dispatcher.py:152\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_core\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    149\u001b[0m flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customize_flags(flags)\n\u001b[1;32m    151\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_implementation(args, {})\n\u001b[0;32m--> 152\u001b[0m cres \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetdescr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtyping_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetdescr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                              \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mpipeline_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Check typing error if object mode is used\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cres\u001b[38;5;241m.\u001b[39mtyping_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m flags\u001b[38;5;241m.\u001b[39menable_pyobject:\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler.py:770\u001b[0m, in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03mParameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m    compiler pipeline\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    768\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    769\u001b[0m                           args, return_type, flags, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler.py:461\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_bytecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler.py:529\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfunc_ir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler.py:508\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mfail_reason \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_final_pipeline:\n\u001b[0;32m--> 508\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompilerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll available pipelines exhausted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler.py:495\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler_machinery.py:368\u001b[0m, in \u001b[0;36mPassManager.run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    365\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m mode pipeline (step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \\\n\u001b[1;32m    366\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, pass_desc)\n\u001b[1;32m    367\u001b[0m patched_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_patch_error(msg, e)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m patched_exception\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m pass_inst \u001b[38;5;241m=\u001b[39m _pass_registry\u001b[38;5;241m.\u001b[39mget(pss)\u001b[38;5;241m.\u001b[39mpass_inst\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runPass\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_inst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLegacy pass in use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler_machinery.py:311\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_initialization, internal_state)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m pass_time:\n\u001b[0;32m--> 311\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m finalize_time:\n\u001b[1;32m    313\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_finalizer, internal_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/compiler_machinery.py:273\u001b[0m, in \u001b[0;36mPassManager._runPass.<locals>.check\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(func, compiler_state):\n\u001b[0;32m--> 273\u001b[0m     mangled \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mangled \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass implementations should return True/False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m did not.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/typed_passes.py:110\u001b[0m, in \u001b[0;36mBaseTypeInference.run_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mType inference and legalization\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fallback_context(state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m failed type inference\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    108\u001b[0m                       \u001b[38;5;241m%\u001b[39m (state\u001b[38;5;241m.\u001b[39mfunc_id\u001b[38;5;241m.\u001b[39mfunc_name,)):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# Type inference\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     typemap, return_type, calltypes, errs \u001b[38;5;241m=\u001b[39m \u001b[43mtype_inference_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypingctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_ir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     state\u001b[38;5;241m.\u001b[39mtypemap \u001b[38;5;241m=\u001b[39m typemap\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# save errors in case of partial typing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/typed_passes.py:91\u001b[0m, in \u001b[0;36mtype_inference_stage\u001b[0;34m(typingctx, targetctx, interp, args, return_type, locals, raise_errors)\u001b[0m\n\u001b[1;32m     89\u001b[0m     infer\u001b[38;5;241m.\u001b[39mbuild_constraint()\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# return errors in case of partial typing\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     errs \u001b[38;5;241m=\u001b[39m \u001b[43minfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     typemap, restype, calltypes \u001b[38;5;241m=\u001b[39m infer\u001b[38;5;241m.\u001b[39munify(raise_errors\u001b[38;5;241m=\u001b[39mraise_errors)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _TypingResults(typemap, restype, calltypes, errs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rt/lib/python3.8/site-packages/numba/core/typeinfer.py:1086\u001b[0m, in \u001b[0;36mTypeInferer.propagate\u001b[0;34m(self, raise_errors)\u001b[0m\n\u001b[1;32m   1083\u001b[0m force_lit_args \u001b[38;5;241m=\u001b[39m [e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m errors\n\u001b[1;32m   1084\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ForceLiteralArg)]\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_lit_args:\n\u001b[0;32m-> 1086\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reduce(operator\u001b[38;5;241m.\u001b[39mor_, force_lit_args)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nNo conversion from array(float64, 2d, C) to array(int64, 1d, A) for '$88return_value.3', defined at None\n\nFile \"../../../../../../../../tmp/ipykernel_52940/1606340820.py\", line 14:\n<source missing, REPL/exec in use?>\n\nDuring: typing of assignment at /tmp/ipykernel_52940/1606340820.py (14)\n\nFile \"../../../../../../../../tmp/ipykernel_52940/1606340820.py\", line 14:\n<source missing, REPL/exec in use?>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@njit(int64[:](float64[:,:], float64[:,:]))\n",
    "def get_spike_bandpower(filt_buffer, power_buffer):\n",
    "    # num_channels, buffer_size = filt_buffer.shape\n",
    "    num_channels, buffer_size=256,30\n",
    "    # logscale=False\n",
    "    for i in range(num_channels):\n",
    "        sum_squared = 0.0\n",
    "        for j in range(buffer_size):\n",
    "\n",
    "            sum_squared += filt_buffer[i,j] * filt_buffer[i,j]\n",
    "        \n",
    "        mean_power = sum_squared \n",
    "        power_buffer[i] = mean_power\n",
    "    return power_buffer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
